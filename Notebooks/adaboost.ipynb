{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6OdVqngP6sFZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, precision_recall_curve\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp7dbSW993yf"
      },
      "source": [
        "I tried comparing between adaboost using skit-learn, lightGBM liberary and XGboost liberary, and using the basic model with no additional optimization skitlearn gave higher accuracy so it is what I will be using"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e635izh6s8S"
      },
      "source": [
        "# loading dataset and checking for outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZsjjRksu6tMK"
      },
      "outputs": [],
      "source": [
        "# Load your dataset\n",
        "file_path = 'Dataset/cleaned_hypertension_data.csv'  # Replace with the path to your dataset\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Outlier detection and removal\n",
        "z_scores = np.abs(stats.zscore(data))\n",
        "data = data[(z_scores < 3).all(axis=1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfqSdv2i62mg"
      },
      "source": [
        "# Finding correlation between features and choosing the top K feastures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Qqbx9af7CG-",
        "outputId": "e76b1b1b-8743-489d-f201-191b434346aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using top 1 features with optimal threshold 0.5045387755369072: Accuracy: 0.725\n",
            "Using top 2 features with optimal threshold 0.49917187361254284: Accuracy: 0.685\n",
            "Using top 3 features with optimal threshold 0.499970619167732: Accuracy: 0.79\n",
            "Using top 4 features with optimal threshold 0.5025145679959081: Accuracy: 0.8125\n",
            "Using top 5 features with optimal threshold 0.5025145679959081: Accuracy: 0.8125\n",
            "Using top 6 features with optimal threshold 0.501703405077917: Accuracy: 0.805\n",
            "Using top 7 features with optimal threshold 0.5024233203277794: Accuracy: 0.805\n",
            "Using top 8 features with optimal threshold 0.4969743937441496: Accuracy: 0.74\n",
            "Using top 9 features with optimal threshold 0.4992962538045883: Accuracy: 0.8825\n",
            "Using top 10 features with optimal threshold 0.4975949879322776: Accuracy: 0.88\n",
            "Using top 11 features with optimal threshold 0.4975949879322776: Accuracy: 0.88\n",
            "Using top 12 features with optimal threshold 0.4975949879322776: Accuracy: 0.88\n"
          ]
        }
      ],
      "source": [
        "# Calculating the correlation matrix\n",
        "correlation_matrix = data.corr()\n",
        "\n",
        "# Extracting correlations with the target variable (assuming the target variable is 'Class')\n",
        "feature_correlation = abs(correlation_matrix[\"Class\"])\n",
        "sorted_features = feature_correlation.sort_values(ascending=False).drop('Class')\n",
        "\n",
        "# Loop to train the model using top k features and print the accuracy for each k\n",
        "for k in range(1, len(sorted_features) + 1):\n",
        "    top_k_features = sorted_features.head(k).index\n",
        "    X = data[top_k_features]\n",
        "    y = data['Class']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    ada_boost_model = AdaBoostClassifier(random_state=42)\n",
        "    ada_boost_model.fit(X_train, y_train)\n",
        "    y_pred_proba = ada_boost_model.predict_proba(X_test)[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    fscore = (2 * precision * recall) / (precision + recall)\n",
        "    ix = np.argmax(fscore)\n",
        "    optimal_threshold = thresholds[ix]\n",
        "    y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Using top {k} features with optimal threshold {optimal_threshold}: Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG05dGUK7HHx"
      },
      "source": [
        "# Manual Hyperparameter tuning using top 9 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MbCvbBu87KML"
      },
      "outputs": [],
      "source": [
        "# Manual Hyperparameter Tuning for top 9 features\n",
        "top_9_features = sorted_features.head(9).index\n",
        "X_top9 = data[top_9_features]\n",
        "y_top9 = data['Class']\n",
        "\n",
        "# Define a range of hyperparameters for tuning\n",
        "n_estimators_range = [50, 100, 150, 200]\n",
        "learning_rate_range = [0.01, 0.1, 1.0]\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "for n_estimators in n_estimators_range:\n",
        "    for learning_rate in learning_rate_range:\n",
        "        model = AdaBoostClassifier(n_estimators=n_estimators, learning_rate=learning_rate, random_state=42)\n",
        "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        cv_results = cross_val_score(model, X_top9, y_top9, cv=skf, scoring='accuracy')\n",
        "        max_accuracy_index = np.argmax(cv_results)\n",
        "        if cv_results[max_accuracy_index] > best_accuracy:\n",
        "            best_accuracy = cv_results[max_accuracy_index]\n",
        "            best_params = {'n_estimators': n_estimators, 'learning_rate': learning_rate}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu2dKuaN7Vmq"
      },
      "source": [
        "# Finding the optimal threshold while training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4NfJ0l7V7ZYx"
      },
      "outputs": [],
      "source": [
        "# Training the best model with optimal threshold\n",
        "best_model = AdaBoostClassifier(**best_params, random_state=42)\n",
        "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(X_top9, y_top9, test_size=0.2, random_state=42)\n",
        "best_model.fit(X_train_final, y_train_final)\n",
        "y_pred_proba_final = best_model.predict_proba(X_test_final)[:, 1]\n",
        "precision_final, recall_final, thresholds_final = precision_recall_curve(y_test_final, y_pred_proba_final)\n",
        "fscore_final = (2 * precision_final * recall_final) / (precision_final + recall_final)\n",
        "ix_final = np.argmax(fscore_final)\n",
        "optimal_threshold_final = thresholds_final[ix_final]\n",
        "y_pred_final = (y_pred_proba_final >= optimal_threshold_final).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkvbslSW7cCn"
      },
      "source": [
        "# Results\n",
        " ( when experementing the focus was on achieving the highest Recal since it's medical data , \"high sensitivity and avoiding false negative is most important\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZpBQc2S77qV",
        "outputId": "8269650d-ba63-4b0a-9c2f-121cab972ad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'n_estimators': 50, 'learning_rate': 0.1}\n",
            "Optimal Threshold: 0.47485040925205974\n",
            "Accuracy: 0.8775\n",
            "Precision: 0.8168316831683168\n",
            "Recall: 0.9322033898305084\n",
            "F1 Score: 0.8707124010554088\n",
            "Confusion Matrix:\n",
            "[[186  37]\n",
            " [ 12 165]]\n"
          ]
        }
      ],
      "source": [
        "precision_final = precision_score(y_test_final, y_pred_final)\n",
        "recall_final = recall_score(y_test_final, y_pred_final)\n",
        "f1_final = f1_score(y_test_final, y_pred_final)\n",
        "conf_matrix_final = confusion_matrix(y_test_final, y_pred_final)\n",
        "\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Optimal Threshold: {optimal_threshold_final}\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test_final, y_pred_final)}\")\n",
        "print(f\"Precision: {precision_final}\")\n",
        "print(f\"Recall: {recall_final}\")\n",
        "print(f\"F1 Score: {f1_final}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix_final}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
