{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV ,KFold\n",
    "import pandas as pd\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/Users/hneen./iCloud Drive (Archive)/Desktop/L9/Graduation project/colon_predicitions/Data/colon-dataset-processed.csv')\n",
    "df = pd.read_csv('../Dataset/cleaned_hypertension_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Class',axis=1)\n",
    "y=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "random_state=123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overampling\n",
    "sm = SMOTE(random_state=random_state)\n",
    "X_oversampled, y_oversampled = sm.fit_resample(X, y)\n",
    "\n",
    "X_train_oversampled, X_test_oversampled, y_train_oversampled, y_test_oversampled = train_test_split(X_oversampled, y_oversampled, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#underampling\n",
    "# rus = RandomUnderSampler(random_state=random_state)\n",
    "rus = SMOTEENN(random_state=random_state, sampling_strategy='all')\n",
    "X_undersampled, y_undersampled = rus.fit_resample(X, y)\n",
    "X_train_undersampled, X_test_undersampled, y_train_undersampled, y_test_undersampled = train_test_split(X_undersampled, y_undersampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "\n",
    "def GridSer_model(model_params,X_train,y_train):\n",
    "    scores = []\n",
    "    cv=KFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "    for model_name, mp in model_params.items():\n",
    "        clf =  GridSearchCV(mp['model'], mp['params'], cv=cv, return_train_score=False,n_jobs=-1,error_score=0)\n",
    "        clf.fit(X_train,y_train)\n",
    "        best_model = mp['model'].set_params(**clf.best_params_)\n",
    "        scores.append({\n",
    "            'best_model': best_model,\n",
    "            'model': model_name,\n",
    "            'best_score': clf.best_score_,\n",
    "            'best_params': clf.best_params_\n",
    "        })\n",
    "    return pd.DataFrame(scores,columns=['best_model','model','best_score','best_params']).sort_values(by=['best_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_training(X_train, y_train, X_test,  y_test, models):\n",
    "    \n",
    "    # Create an empty DataFrame to store results\n",
    "    results_df = pd.DataFrame(columns=['Model', 'Accuracy'])\n",
    "\n",
    "    for model in models:\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        # Make predictions\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision =precision_score(y_test, predictions)\n",
    "        recall= recall_score(y_test, predictions)\n",
    "        cm=confusion_matrix(y_test, predictions)\n",
    "        labels=model.classes_\n",
    "        \n",
    "        # Append results to the DataFrame\n",
    "        temp_df = pd.DataFrame({'Model': [model.__class__.__name__], 'Accuracy': [accuracy], 'Precision': [precision], 'recall': [recall], 'cm':[cm],'labels':[labels]})\n",
    "        results_df = pd.concat([results_df, temp_df], ignore_index=True)\n",
    "\n",
    "\n",
    "    # Sort and return the results DataFrame\n",
    "    return results_df.sort_values(by=['Accuracy'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \n",
    "    'XGBClassifier' : {\n",
    "        'model': XGBClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200], \n",
    "            'learning_rate': [0.01, 0.1, 1],\n",
    "            'max_depth': [3, 5, 10],\n",
    "            'gamma': [0, 0.1, 0.5, 1],\n",
    "            'subsample': [0.5, 0.75, 1],\n",
    "            'colsample_bytree': [0.5, 0.75, 1],\n",
    "            'lambda': [0.0, 0.1, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'KNeighborsClassifier': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'n_neighbors': [3, 5, 10, 15],  # Number of neighbors to use\n",
    "            'weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
    "            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm used to compute the nearest neighbors\n",
    "            'leaf_size': [10, 30, 50, 70],  # Leaf size passed to BallTree or KDTree\n",
    "            'p': [1, 2]  # Power parameter for the Minkowski metric\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'SVM':{\n",
    "            'model': SVC(),\n",
    "            'params': {\n",
    "                'C': [0.1, 1, 10, 100], \n",
    "                'kernel': ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "            }\n",
    "    },  \n",
    "    \n",
    "    'ExtraTreesClassifier' : {\n",
    "        'model': ExtraTreesClassifier(),\n",
    "        'params': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 4, 6],\n",
    "        'min_samples_leaf': [1, 2, 3],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "        }\n",
    "    },    \n",
    "    \n",
    "    'HistGradientBoostingClassifier':{\n",
    "        'model': HistGradientBoostingClassifier(),\n",
    "        'params': {\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "            'max_iter': [50, 100, 200],\n",
    "            'max_leaf_nodes': [15, 31, 63, 127],\n",
    "            'min_samples_leaf': [5, 10, 20],\n",
    "            'l2_regularization': [0.0, 0.1, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'RandomForestClassifier' : {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 4, 6],\n",
    "            'min_samples_leaf': [1, 2, 3],\n",
    "            'max_features': ['auto', 'sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'DecisionTreeClassifier':{\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'AdaBoostClassifier' : {\n",
    "        'model': AdaBoostClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200], \n",
    "            'learning_rate': [0.01, 0.1, 1]\n",
    "        }\n",
    "    } ,\n",
    "\n",
    "    'LogisticRegression' : {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10, 100], \n",
    "            'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = GridSer_model(model_params,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original['best_params'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=original['best_model'].tolist()\n",
    "model_training(X_train, y_train, X_test, y_test, models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_grd=GridSer_model(model_params,X_train_oversampled,y_train_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_grd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_oversampled_grd=oversampled_grd['best_model'].tolist()\n",
    "model_training(X_train_oversampled, y_train_oversampled, X_test_oversampled, y_test_oversampled, models_oversampled_grd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampled_grd=GridSer_model(model_params,X_train_undersampled,y_train_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampled_grd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampled_grd['best_params'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_undersampled_grd=undersampled_grd['best_model'].tolist()\n",
    "models_undersampled_grd_t=model_training(X_train_undersampled, y_train_undersampled, X_test_undersampled, y_test_undersampled, models_undersampled_grd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_undersampled_grd_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=models_undersampled_grd_t['cm'][0]\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('AdaBoostClassifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_undersampled_grd_t\n",
    "cm=models_undersampled_grd_t['cm'][1]\n",
    "cm\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('HistGradientBoostingClassifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_undersampled_grd_t\n",
    "cm=models_undersampled_grd_t['cm'][2]\n",
    "cm\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('ExtraTreesClassifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(models_undersampled_grd[0], open('/Users/shahadaleissa/Downloads/Code/SMOTEENN_Models/Adaboost_SMOTEENN.pkl','wb'))\n",
    "# pickle.dump(models_undersampled_grd[2], open('/Users/shahadaleissa/Downloads/Code/SMOTEENN_Models/ET_SMOTEENN.pkl','wb'))\n",
    "# pickle.dump(models_undersampled_grd[1], open('/Users/shahadaleissa/Downloads/Code/SMOTEENN_Models/HGB_SMOTEENN.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
