{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Level_of_Hemoglobin</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Physical_activity</th>\n",
       "      <th>salt_content_in_the_diet</th>\n",
       "      <th>Level_of_Stress</th>\n",
       "      <th>Chronic_kidney_disease</th>\n",
       "      <th>Adrenal_and_thyroid_disorders</th>\n",
       "      <th>Genetic_Pedigree_Coefficient</th>\n",
       "      <th>alcohol_consumption_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11.28</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45961</td>\n",
       "      <td>48071</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>336.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9.75</td>\n",
       "      <td>54</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26106</td>\n",
       "      <td>25333</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10.79</td>\n",
       "      <td>70</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9995</td>\n",
       "      <td>29465</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>71</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10635</td>\n",
       "      <td>7439</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14.17</td>\n",
       "      <td>52</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15619</td>\n",
       "      <td>49644</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1</td>\n",
       "      <td>10.14</td>\n",
       "      <td>69</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26118</td>\n",
       "      <td>47568</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1</td>\n",
       "      <td>11.77</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2572</td>\n",
       "      <td>8063</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>299.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1</td>\n",
       "      <td>16.91</td>\n",
       "      <td>18</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14933</td>\n",
       "      <td>24753</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>369.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>11.15</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18157</td>\n",
       "      <td>15275</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "      <td>253.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1</td>\n",
       "      <td>11.36</td>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20729</td>\n",
       "      <td>30463</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>230.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class  Level_of_Hemoglobin  Age  BMI  Sex  Smoking  Physical_activity  \\\n",
       "0         1                11.28   34   23    1        0              45961   \n",
       "1         0                 9.75   54   33    1        0              26106   \n",
       "2         1                10.79   70   49    0        0               9995   \n",
       "3         0                11.00   71   50    0        0              10635   \n",
       "4         1                14.17   52   19    0        0              15619   \n",
       "...     ...                  ...  ...  ...  ...      ...                ...   \n",
       "1995      1                10.14   69   26    1        1              26118   \n",
       "1996      1                11.77   24   45    1        1               2572   \n",
       "1997      1                16.91   18   42    0        0              14933   \n",
       "1998      0                11.15   46   45    1        1              18157   \n",
       "1999      1                11.36   41   45    0        0              20729   \n",
       "\n",
       "      salt_content_in_the_diet  Level_of_Stress  Chronic_kidney_disease  \\\n",
       "0                        48071                2                       1   \n",
       "1                        25333                3                       0   \n",
       "2                        29465                2                       1   \n",
       "3                         7439                1                       1   \n",
       "4                        49644                2                       0   \n",
       "...                        ...              ...                     ...   \n",
       "1995                     47568                3                       1   \n",
       "1996                      8063                3                       1   \n",
       "1997                     24753                2                       1   \n",
       "1998                     15275                3                       0   \n",
       "1999                     30463                1                       1   \n",
       "\n",
       "      Adrenal_and_thyroid_disorders  Genetic_Pedigree_Coefficient  \\\n",
       "0                                 1                          0.90   \n",
       "1                                 0                          0.23   \n",
       "2                                 0                          0.91   \n",
       "3                                 0                          0.43   \n",
       "4                                 0                          0.83   \n",
       "...                             ...                           ...   \n",
       "1995                              0                          0.02   \n",
       "1996                              1                          1.00   \n",
       "1997                              1                          0.22   \n",
       "1998                              1                          0.72   \n",
       "1999                              0                          0.09   \n",
       "\n",
       "      alcohol_consumption_per_day  \n",
       "0                      336.333333  \n",
       "1                      205.000000  \n",
       "2                       67.000000  \n",
       "3                      242.000000  \n",
       "4                      397.000000  \n",
       "...                           ...  \n",
       "1995                   144.000000  \n",
       "1996                   299.666667  \n",
       "1997                   369.000000  \n",
       "1998                   253.000000  \n",
       "1999                   230.000000  \n",
       "\n",
       "[2000 rows x 13 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('../Dataset/cleaned_hypertension_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids, TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def splitting_data(df, sampling):\n",
    "    X = df.drop(['Class'], axis=1)\n",
    "    y = df['Class']\n",
    "\n",
    "    if sampling == 'none':\n",
    "        return X, y\n",
    "    elif sampling == 'SMOTEENN':\n",
    "        sampler = SMOTEENN(random_state=0)\n",
    "    elif sampling == 'SMOTE':\n",
    "        sampler = SMOTE(random_state=0)\n",
    "    elif sampling == 'under':\n",
    "        sampler = RandomUnderSampler(random_state=0)\n",
    "    elif sampling == 'over':\n",
    "        sampler = RandomOverSampler(random_state=0)\n",
    "    elif sampling == 'cluster_centroids':\n",
    "        sampler = ClusterCentroids(random_state=0)\n",
    "    elif sampling == 'tomek_links':\n",
    "        sampler = TomekLinks()\n",
    "\n",
    "    X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X_train, y_train):\n",
    "    # Create a KNN classifier with 5 neighbors\n",
    "    DT = DecisionTreeClassifier(random_state=random_state)\n",
    "    # Fit the classifier to the data\n",
    "    DT.fit(X_train, y_train)\n",
    "    return DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(DT, X_test ,y_test):\n",
    "    # Predict the labels for the training data X\n",
    "    y_pred = DT.predict(X_test)\n",
    "    cr=classification_report(y_test, y_pred)\n",
    "    print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def optimize(X,y):\n",
    "#     k_values = [i for i in range (1,31)]\n",
    "#     scores = []\n",
    "\n",
    "#     scaler = StandardScaler()\n",
    "#     X = scaler.fit_transform(X)\n",
    "\n",
    "#     for k in k_values:\n",
    "#         knn = KNeighborsClassifier(n_neighbors=k)\n",
    "#         score = cross_val_score(knn, X, y, cv=5)\n",
    "#         scores.append(np.mean(score))\n",
    "\n",
    "#     best_index = np.argmax(scores)\n",
    "#     best_k = k_values[best_index]\n",
    "\n",
    "#     return best_k, scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def optimize_with_grid(X_train, y_train):\n",
    "    # Define a pipeline that first scales the data and then applies the classifier\n",
    "    pipe = Pipeline([\n",
    "        # ('scaler', StandardScaler()),\n",
    "        ('dt', DecisionTreeClassifier(random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid to search\n",
    "    param_grid = {\n",
    "        'dt__max_depth': [None, 10, 20, 30, 40, 50],\n",
    "        'dt__min_samples_split': [2, 5, 10],\n",
    "        'dt__min_samples_leaf': [1, 2, 4],\n",
    "        'dt__criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    DT_cv = GridSearchCV(pipe,param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "    # Perform the grid search on the provided data\n",
    "    DT_cv.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters and best score\n",
    "    best_params = DT_cv.best_params_\n",
    "    best_score = DT_cv.best_score_\n",
    "    best_estimator = DT_cv.best_estimator_\n",
    "    print(best_params)\n",
    "    print(best_score)\n",
    "\n",
    "    return best_estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT on original data with optimization </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using function with no sampling \n",
    "X, y= splitting_data(df, 'none')\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "0    1013\n",
      "1     987\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       191\n",
      "           1       0.86      0.82      0.84       209\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.84      0.84       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT1 =training(X_train, y_train)\n",
    "y_pred = predict(DT1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'entropy', 'dt__max_depth': 10, 'dt__min_samples_leaf': 4, 'dt__min_samples_split': 10}\n",
      "0.85125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85       191\n",
      "           1       0.88      0.85      0.86       209\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.86      0.86      0.86       400\n",
      "weighted avg       0.86      0.86      0.86       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT1 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict(best_DT1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT using SMOTE sampling </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(df, 'SMOTE')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "1    1013\n",
      "0    1013\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83       211\n",
      "           1       0.81      0.82      0.81       195\n",
      "\n",
      "    accuracy                           0.82       406\n",
      "   macro avg       0.82      0.82      0.82       406\n",
      "weighted avg       0.82      0.82      0.82       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT2 =training(X_train, y_train)\n",
    "y_pred = predict(DT2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': 10, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 5}\n",
      "0.8456790123456791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86       211\n",
      "           1       0.86      0.83      0.84       195\n",
      "\n",
      "    accuracy                           0.85       406\n",
      "   macro avg       0.85      0.85      0.85       406\n",
      "weighted avg       0.85      0.85      0.85       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT2 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict(best_DT2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT using SMOTEENN sampling </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(df, 'SMOTEENN')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the set:\n",
      "1    151\n",
      "0    137\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in each class in the set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.76      0.72        25\n",
      "           1       0.80      0.73      0.76        33\n",
      "\n",
      "    accuracy                           0.74        58\n",
      "   macro avg       0.74      0.74      0.74        58\n",
      "weighted avg       0.75      0.74      0.74        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn5 =training(X_train, y_train)\n",
    "y_pred = predict(knn5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 5}\n",
      "0.8304347826086957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.72      0.69        25\n",
      "           1       0.77      0.73      0.75        33\n",
      "\n",
      "    accuracy                           0.72        58\n",
      "   macro avg       0.72      0.72      0.72        58\n",
      "weighted avg       0.73      0.72      0.73        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_knn = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict(best_knn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT on Random undersampling </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(df, 'under')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the set:\n",
      "0    987\n",
      "1    987\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in each class in the set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       200\n",
      "           1       0.84      0.78      0.81       195\n",
      "\n",
      "    accuracy                           0.82       395\n",
      "   macro avg       0.82      0.82      0.82       395\n",
      "weighted avg       0.82      0.82      0.82       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn7 =training(X_train, y_train)\n",
    "y_pred = predict(knn7, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': 10, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}\n",
      "0.8492726542093629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       200\n",
      "           1       0.85      0.76      0.80       195\n",
      "\n",
      "    accuracy                           0.82       395\n",
      "   macro avg       0.82      0.81      0.81       395\n",
      "weighted avg       0.82      0.82      0.81       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_knn = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict(best_knn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT on Cluster Centroids </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X,y = splitting_data(df, 'cluster_centroids')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the set:\n",
      "0    987\n",
      "1    987\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in each class in the set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       200\n",
      "           1       0.85      0.82      0.83       195\n",
      "\n",
      "    accuracy                           0.84       395\n",
      "   macro avg       0.84      0.84      0.84       395\n",
      "weighted avg       0.84      0.84      0.84       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn7 =training(X_train, y_train)\n",
    "y_pred = predict(knn7, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'entropy', 'dt__max_depth': 10, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}\n",
      "0.8600321478802491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       200\n",
      "           1       0.85      0.77      0.81       195\n",
      "\n",
      "    accuracy                           0.82       395\n",
      "   macro avg       0.83      0.82      0.82       395\n",
      "weighted avg       0.83      0.82      0.82       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_knn = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict(best_knn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT on Tomek Links </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(df, 'tomek_links')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the set:\n",
      "1    987\n",
      "0    694\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in each class in the set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80       139\n",
      "           1       0.86      0.86      0.86       198\n",
      "\n",
      "    accuracy                           0.84       337\n",
      "   macro avg       0.83      0.83      0.83       337\n",
      "weighted avg       0.84      0.84      0.84       337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn7 =training(X_train, y_train)\n",
    "y_pred = predict(knn7, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'entropy', 'dt__max_depth': 10, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 10}\n",
      "0.8512067913221995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       139\n",
      "           1       0.90      0.85      0.88       198\n",
      "\n",
      "    accuracy                           0.86       337\n",
      "   macro avg       0.85      0.86      0.85       337\n",
      "weighted avg       0.86      0.86      0.86       337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_knn = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict(best_knn, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
