{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InaVxMa-rIsd"
      },
      "source": [
        "# Comparing the performance of 3 liberaries using basic logistic regression models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfBW-zA1tf9S"
      },
      "source": [
        "### 1- siket-learn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKQN8iWGoSkj",
        "outputId": "edf639df-5d22-4d65-b363-c9058b98f191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scikit-learn Accuracy: 0.735\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('/Users/shahadaleissa/hyper_code/Dataset/cleaned_hypertension_data.csv')\n",
        "\n",
        "# Split data into features and target\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "#standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Create Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and accuracy\n",
        "predictions = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Scikit-learn Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tuned hpyerparameters :(best parameters)  {'C': 0.1, 'penalty': 'l2'}\n",
            "accuracy : 0.697857142857143\n"
          ]
        }
      ],
      "source": [
        "# Grid search cross validation\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "cv=KFold(n_splits=5,random_state=42,shuffle=True)\n",
        "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\"]}# l1 lasso l2 ridge\n",
        "logreg=LogisticRegression()\n",
        "logreg_cv=GridSearchCV(logreg,grid,cv=cv)\n",
        "logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
        "print(\"accuracy :\",logreg_cv.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best model accuracy: 0.735\n"
          ]
        }
      ],
      "source": [
        "#best model\n",
        "best_model=LogisticRegression(C=0.1,penalty=\"l2\")\n",
        "best_model.fit(X_train,y_train)\n",
        "print(\"best model accuracy:\",best_model.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-9fLEaPtox3"
      },
      "source": [
        "### 2- statsmodels model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfMxOWJupMK9",
        "outputId": "868fed4f-2127-4886-9eca-a5e9b4beed18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.538264\n",
            "         Iterations 6\n",
            "Statsmodels Accuracy: 0.735\n"
          ]
        }
      ],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Add constant to features\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create Logistic Regression model\n",
        "model = sm.Logit(y_train, X_train)\n",
        "result = model.fit()\n",
        "\n",
        "# Predictions and accuracy\n",
        "predictions = result.predict(X_test)\n",
        "predictions = round(predictions)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Statsmodels Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjKNExV7tuo1"
      },
      "source": [
        "### 3- tensorflow model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8jDxhcbrbaM",
        "outputId": "08f072d6-81bc-4b59-9863-fe2b1092d15c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Accuracy: 0.4833333194255829\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert data to TensorFlow tensors\n",
        "X_train = tf.convert_to_tensor(X_train.values, dtype=tf.float32)\n",
        "X_test = tf.convert_to_tensor(X_test.values, dtype=tf.float32)\n",
        "y_train = tf.convert_to_tensor(y_train.values, dtype=tf.float32)\n",
        "y_test = tf.convert_to_tensor(y_test.values, dtype=tf.float32)\n",
        "\n",
        "# Create Logistic Regression model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, verbose=0)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"TensorFlow Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkDN9Vfnt5lp"
      },
      "source": [
        "based on the 3 comparisons statsmodels had the best performance so i will proceed with that library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0jZHxwA8QHz"
      },
      "source": [
        "techniques like hyper paramater tuning or data transformation had no impact on the accuracy of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfcBcglv8e9k"
      },
      "source": [
        "## trying different resampling techniques SMOTE showed better results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV9mSM0b2B7X",
        "outputId": "9ba52da7-87f2-43ff-beeb-6457721323fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with oversample: 0.7316666666666667\n",
            "Accuracy with smote: 0.7383333333333333\n",
            "Accuracy with undersample: 0.7366666666666667\n",
            "Best technique: smote with an accuracy of 0.7383333333333333\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Resampling techniques\n",
        "techniques = ['oversample', 'smote', 'undersample']\n",
        "accuracy_results = {}\n",
        "\n",
        "for technique in techniques:\n",
        "    # Resampling\n",
        "    if technique == 'oversample':\n",
        "        resampler = RandomOverSampler(random_state=42)\n",
        "    elif technique == 'smote':\n",
        "        resampler = SMOTE(random_state=42)\n",
        "    elif technique == 'undersample':\n",
        "        resampler = RandomUnderSampler(random_state=42)\n",
        "\n",
        "    X_resampled, y_resampled = resampler.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Create and fit the logistic regression model\n",
        "    X_train_const = sm.add_constant(X_resampled)\n",
        "    X_test_const = sm.add_constant(X_test)\n",
        "    model = sm.Logit(y_resampled, X_train_const)\n",
        "    result = model.fit(disp=0)\n",
        "\n",
        "    # Predict and calculate accuracy\n",
        "    predictions = result.predict(X_test_const)\n",
        "    predictions = (predictions > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "    accuracy_results[technique] = accuracy\n",
        "    print(f\"Accuracy with {technique}: {accuracy}\")\n",
        "\n",
        "# Output the best technique based on accuracy\n",
        "best_technique = max(accuracy_results, key=accuracy_results.get)\n",
        "print(f\"Best technique: {best_technique} with an accuracy of {accuracy_results[best_technique]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHiR20Ym8uA5"
      },
      "source": [
        "### statemodels model with SMOTE and stratified cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3w4sMOT8_2U",
        "outputId": "ebf10141-5be7-4dd6-9ff0-71c8d0d29b65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy after SMOTE (before CV): 0.7161895360315893\n",
            "Final Accuracy (after CV): 0.755\n",
            "Precision: 0.7358490566037735\n",
            "Recall: 0.7878787878787878\n",
            "F1-Score: 0.7609756097560976\n",
            "Confusion Matrix:\n",
            "[[73 28]\n",
            " [21 78]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Function for 10-fold stratified cross-validation with SMOTE\n",
        "def stratified_cv_smote(X, y):\n",
        "    skf = StratifiedKFold(n_splits=10)\n",
        "    best_fold_metrics = None\n",
        "    highest_accuracy = 0\n",
        "    fold_number = 1\n",
        "    best_fold_number = 0\n",
        "\n",
        "    # Calculate accuracy after SMOTE and before cross-validation\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "    model = sm.Logit(y_smote, sm.add_constant(X_smote))\n",
        "    result = model.fit(disp=0)\n",
        "    predictions_smote = result.predict(sm.add_constant(X_smote))\n",
        "    predictions_smote = (predictions_smote > 0.5).astype(int)\n",
        "    accuracy_smote = accuracy_score(y_smote, predictions_smote)\n",
        "    print(f\"Accuracy after SMOTE (before CV): {accuracy_smote}\")\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        # Apply SMOTE\n",
        "        X_train_smote, y_train_smote = smote.fit_resample(X_train_fold, y_train_fold)\n",
        "\n",
        "        # Fit model\n",
        "        X_train_smote_const = sm.add_constant(X_train_smote)\n",
        "        X_test_smote_const = sm.add_constant(X_test_fold)\n",
        "        model = sm.Logit(y_train_smote, X_train_smote_const)\n",
        "        result = model.fit(disp=0)\n",
        "\n",
        "        # Predict and calculate metrics\n",
        "        predictions = result.predict(X_test_smote_const)\n",
        "        predictions = (predictions > 0.5).astype(int)\n",
        "        accuracy = accuracy_score(y_test_fold, predictions)\n",
        "\n",
        "        if accuracy > highest_accuracy:\n",
        "            highest_accuracy = accuracy\n",
        "            best_fold_number = fold_number\n",
        "            best_fold_metrics = {\n",
        "                \"accuracy\": accuracy,\n",
        "                \"precision\": precision_score(y_test_fold, predictions),\n",
        "                \"recall\": recall_score(y_test_fold, predictions),\n",
        "                \"f1\": f1_score(y_test_fold, predictions),\n",
        "                \"confusion_matrix\": confusion_matrix(y_test_fold, predictions)\n",
        "            }\n",
        "\n",
        "        fold_number += 1\n",
        "\n",
        "    #print(f\"Highest accuracy was in fold {best_fold_number}: {highest_accuracy}\")\n",
        "    return best_fold_metrics\n",
        "\n",
        "# Apply 10-fold stratified cross-validation with SMOTE\n",
        "results = stratified_cv_smote(X, y)\n",
        "\n",
        "# Print out the results\n",
        "print(f\"Final Accuracy (after CV): {results['accuracy']}\")\n",
        "print(f\"Precision: {results['precision']}\")\n",
        "print(f\"Recall: {results['recall']}\")\n",
        "print(f\"F1-Score: {results['f1']}\")\n",
        "print(f\"Confusion Matrix:\\n{results['confusion_matrix']}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
